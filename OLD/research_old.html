<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">

<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<meta name="keywords" content="">
	<meta name="description" content="">

	<title>Research | Feature Selection @ ASU</title>

	<link href="./style/style.css" rel="stylesheet" type="text/css" media="screen">
	<link rel="shortcut icon" href="./images/favicon.ico">
	<script type="text/javascript" async="" src="./js/ga.js"></script>

</head>

<body>

	<div id="header">
		<div id="logo">
			<h1><a href="home_old.html">Feature Selection</a></h1>
			<p>at <a href="http://asu.edu/">Arizona State University</a></p>
			<br>
			In conjunction with the <a href="http://dmml.asu.edu/">DMML</a>.
		</div>
	</div>
	<!-- end #header -->

	<div id="menu">
		<ul>
			<li><a href="home_old.html">Home</a></li>
			<li><a href="research_old.html">Research</a></li>
			<li><a href="datasets_old.html">Datasets</a></li>
			<li><a href="algorithms_old.html">Feature Selection Algorithms</a></li>
		</ul>
	</div>
	<!-- end #menu -->



	<div id="page">
		<div id="content">
			<div class="post">
				<h1 class="title"><a href="research_old.html#">Research</a></h1>

				<ul>
					<li><a href="research_old.html#grants">Grants</a></li><a href="research_old.html#grants">
					</a>
					<li><a href="research_old.html#grants"></a><a href="research_old.html#research">Research</a></li><a
						href="research_old.html#research">
					</a>
				</ul><a href="research_old.html#research">

				</a>
				<div class="entry"><a href="research_old.html#research">
					</a><a name="grants">
						<h2 class="STYLE1">NSF Grant</h2>
					</a>
					<h4 class="STYLE1">Description</h4>
					<p>High-dimensional data is ubiquitous in real-world applications - from text categorization, to
						image processing, and to Web searches. The shortage of labeled data, resulting from high
						labeling costs, necessitates the need to explore machine learning approaches beyond classic
						classification and clustering paradigms. Semi-supervised learning is one such approach that
						demonstrates its potential in handling data with small labeled samples and reducing the need for
						expensive labeled data. However, high-dimensional data with small labeled samples permits too
						large a hypothesis space yet with too few constraints (labeled instances). The combination of
						the two data characteristics manifests a new research challenge. Employing computational and
						statistical learning theory, we analyze specific challenges presented by such data, show
						preliminary studies, delineate the need to integrate feature selection and extraction in a novel
						framework to reduce hypothesis space, propose to design efficient and novel algorithms, and
						conduct theoretical and empirical studies to understand complex relationships between
						high-dimensional data and classification performance.</p>
					<h4 class="STYLE1">Publications</h4>
					<ul style="margin-top:0in" type="disc">
						<li class="MsoNormal"><b>Journal Articles</b> </li>
						<ul style="margin-top:0in" type="circle">
							<li class="MsoNormal">Z. Zhao and H. Liu. "Multi-Source Feature Selection
								via Geometry-Dependent Covariance Analysis", JMLR Workshop and
								Conference Proceedings Volume 4: New challenges for feature selection in
								data mining and knowledge discovery, 4:36-47, 2008</li>
							<li class="MsoNormal">Z. Zhao and H. Liu. "Searching for Interacting
								Features in Subset Selection", Intelligent Data Analysis - An
								International Journal, 13:207-228, 2009. </li>
							<li class="MsoNormal">M. Berens, H. Liu, L. Parsons, L. Yu, and Z. Zhao.
								“Fostering Biological Relevance in Feature Selection for Microarray
								Data”, Trends and Controversies,[<a
									href="http://www.public.asu.edu/~huanliu/papers/ieeeis05.pdf">PDF]</a>, pp
								71 - 73. November/December 2005, IEEE Intelligent Systems.</li>
							<li class="MsoNormal">H. Liu and L. Yu. "Toward Integrating Feature
								Selection Algorithms for Classification and Clustering", <a
									href="http://csdl2.computer.org/persagen/DLAbsToc.jsp?resourcePath=/dl/trans/tk/&amp;toc=comp/trans/tk/2005/04/k4toc.xml&amp;DOI=10.1109/TKDE.2005.66">IEEE
									Trans. on Knowledge and Data Engineering</a>,&nbsp;<a
									href="http://www.public.asu.edu/~huanliu/papers/tkde05.pdf">pdf</a>,
								17(4), 491-502, 2005. </li>
							<li class="MsoNormal">Jieping Ye, Jianhui Chen, Ravi Janardan, and Sudhir
								Kumar. Developmental Stage Annotation of <i>Drosophila</i> Gene Expression
								Pattern Images via an Entire Solution Path for LDA. <b><i><a
											href="http://tkdd.cs.uiuc.edu/">ACM Transactions on Knowledge Discovery
											from Data</a></i></b>. special issue on Bioinformatics. Vol. 2, No. 1,
								pp. 1-21, 2008. [ <a
									href="http://portal.acm.org/citation.cfm?id=1342320.1342324&amp;coll=portal&amp;dl=ACM&amp;idx=J1054&amp;part=transaction&amp;WantType=Transactions&amp;title=TKDD&amp;CFID=49478026&amp;CFTOKEN=97837260">PDF</a>]
							</li>
						</ul>
					</ul>

					<ul style="margin-top:0in" type="disc">
						<li class="MsoNormal"><b>Conferences and Workshops</b>
							<ul>
								<li> Z. Zhao, L. Wang, and H. Liu. Efficient Spectral Feature Selection with Minimum
									Redundancy. In Proceedings of the Twenty-Fourth AAAI Conference on Artificial
									Intelligence (AAAI), 2010 . [<a
										href="http://www.public.asu.edu/~zzhao15/papers/zhengzhao_AAAI_2010.pdf">PDF</a>,
									<a
										href="http://www.public.asu.edu/~zzhao15/papers/zhengzhao_AAAI_2010_appendix.pdf">Supplementary</a>]
								</li>
								<li> Z. Zhao, J. Wang, S. Sharma, N. Agarwal, H. Liu, and Y. Chang. An Integrative
									Approach to Identifying Biologically Relevant Genes. In Proceedings of SIAM
									International Conference on Data Mining (SDM), 2010. [<a
										href="http://www.public.asu.edu/~zzhao15/papers/SDM-ZZHAO-10.pdf">PDF</a>]</li>

								<li> Z. Zhao, J. Wang, H. Liu, and Y. Chang. Biological relevance detection via network
									dynamic analysis. In Proceedings of 2nd International Conference on Bioinformatics
									and Computational Biology (BICoB), 2010. <a
										href="http://picasaweb.google.com/Mary.Ann.Sullivan2/CATABICoB2010PICS?feat=email#5455352633272872050">BEST
										PAPER AWARD</a> [<a
										href="http://www.public.asu.edu/~zzhao15/papers/BICoB-ZZHAO-10.pdf">PDF</a>]
								</li>

								<li>J. Liu, L. Yuan, and J. Ye. An Efficient Algorithm for a Class of Fused Lasso
									Problems. The Sixteenth ACM SIGKDD International Conference On Knowledge Discovery
									and Data Mining (SIGKDD 2010). [<a
										href="http://www.public.asu.edu/~jye02/Publications/Papers/rp589f-liu.pdf">PDF</a>]
								</li>
								<li>L. Sun, B. Ceran, and J. Ye. A Scalable Two-Stage Approach for a Class of
									Dimensionality Reduction Techniques. The Sixteenth ACM SIGKDD International
									Conference On Knowledge Discovery and Data Mining (SIGKDD 2010). </li>
								<li>J. Chen, J. Liu, and J. Ye. Learning Incoherent Sparse and Low-Rank Patterns from
									Multiple Tasks. The Sixteenth ACM SIGKDD International Conference On Knowledge
									Discovery and Data Mining (SIGKDD 2010). <br>
								</li>
								<li>H. Liu, H. Motoda, R. Setiono, and Z. Zhao. Feature Selection: An Ever Evolving
									Frontier in Data Mining, Journal of Machine Learning Research, Workshop and
									Conference Proceedings Volume 10, 10:4-13, 2010.[<a
										href="http://proceedings.mlr.press/v10/liu10b/liu10b.pdf">PDF</a>]
								</li>
								<li>L. Sun, J. Liu, J. Chen, and J. Ye. Efficient Recovery of Jointly Sparse Vectors.
									The Twenty-Third Annual Conference on Neural Information Processing Systems (NIPS
									2009). [<a
										href="http://www.public.asu.edu/~jye02/Publications/Papers/NIPS09_1056.pdf">PDF</a>]
								</li>
								<li>J. Liu, S. Ji, and J. Ye. Multi-task Feature Learning via Efficient L2,1-Norm
									Minimization. The Twenty-fifth Conference on Uncertainty in Artificial Intelligence
									(UAI 2009).[<a
										href="http://www.public.asu.edu/~jye02/Publications/Papers/Liu_UAI09.pdf">PDF</a>]
								</li>
								<li>J. Liu, J. Chen, and J. Ye. Large-Scale Sparse Logistic Regression. The Fifteenth
									ACM SIGKDD International Conference On Knowledge Discovery and Data Mining (SIGKDD
									2009), pp. 547-556. </li>
								<li>L. Sun, S. Ji, and J. Ye. A Least Squares Formulation for a Class of Generalized
									Eigenvalue Problems in Machine Learning. The Twenty-Sixth International Conference
									on Machine Learning (ICML 2009). [<a
										href="http://www.cs.mcgill.ca/~icml2009/papers/315.pdf">PDF</a>] </li>
								<li>S. Ji and J. Ye. Linear Dimensionality Reduction for Multi-label Classification. The
									Twenty-first International Joint Conference on Artificial Intelligence (IJCAI
									2009).[<a
										href="http://www.public.asu.edu/~jye02/Publications/Papers/mldr-ijcai09.pdf">PDF</a>]
								</li>
								<li>Z. Zhao, J. Wang, S. Sharma, N. Agarwal, H. Liu and Y. Chang. " A Knowledge-Oriented
									Framework for Gene Selection", Poster. Tuscon, Arizona, May 18-21. RECOMB'09</li>
								<li>Z. Zhao, L. Sun, S. Yu, H. Liu, J. Ye. "Multiclass Probabilistic Kernel Discriminant
									Analysis", IJCAI'09 [<a
										href="http://www.public.asu.edu/~zzhao15/papers/ZZHAO-IJCAI-1453.pdf">PDF</a>]
								</li>
							</ul>
						</li>
						<ul style="margin-top:0in" type="circle">
							<li class="MsoNormal">Z. Zhao, J. Wang, H. Liu, J. Ye, and Y. Chang.
								"Identifying Biologically Relevant Genes via Multiple Heterogeneous
								Data Sources", KDD'08: 839 - 847. [<a
									href="http://www.public.asu.edu/~huanliu/papers/kdd08Zhao.pdf">PDF</a>]</li>
							<li class="MsoNormal">Z. Zhao and H. Liu. ``Spectral Feature Selection for
								Supervised and Unsupervised Learning''. International Conference on Machine
								Learning (ICML-07), June 20-24, 2007, Corvallis, Oregon. [<a
									href="http://www.public.asu.edu/~huanliu/papers/icml07.pdf">PDF</a>]</li>
							<li class="MsoNormal">Z. Zhao and H. Liu. ``Semi-supervised Feature Selection
								via Spectral Analysis", SIAM International Conference on Data Mining
								(<a href="http://www.siam.org/meetings/sdm07/">SDM-07</a>), April&nbsp;
								26-28, 2007, Minneapolis, Minnesoda. [<a
									href="http://www.public.asu.edu/~huanliu/papers/sdm07.pdf">PDF</a>]</li>
							<li class="MsoNormal">Z. Zhao and H. Liu. ``Searching for Interacting
								Features", The 20th International Joint Conference on AI (<a
									href="http://www.ijcai-07.org/">IJCAI-07</a>), January 6-12 Hyderabad,
								India. [<a href="http://www.public.asu.edu/~huanliu/papers/ijcai07.pdf">PDF</a>].
								<a href="http://www.public.asu.edu/~huanliu/INTERACT/INTERACTsoftware.html">Software
									available</a>. </li>
							<li class="MsoNormal">Jieping Ye<b>. </b>Least Squares Linear Discriminant
								Analysis.<b> </b><i>The Twenty-Fourth International Conference on Machine
									Learning</i> (<a href="http://oregonstate.edu/conferences/icml2007/">ICML
									2007</a>), pp. 1087-1093<i>.</i> Technical Report <span style="color:blue"><a
										href="http://sci.asu.edu/news/technical/TR_year.php?pub_date=2006">TR-06-003</a></span>,
								Department of Computer Science and Engineering, Arizona State University
								, March, 2006. [<a
									href="http://www.public.asu.edu/~jye02/Publications/PDF/LS-LDA_icml07.pdf">PDF</a>]
							</li>
						</ul>
					</ul>

					<ul style="margin-top:0in" type="disc">
						<li class="MsoNormal"><b>Books or Chapters</b> </li>
						<ul style="margin-top:0in" type="circle">
							<li class="MsoNormal">Huan Liu and Hiroshi Motoda, "Feature Selection for
								Knowledge Discovery and Data Mining", July 1998, ISBN 0-7923-8198-X,
								by <a href="http://www.wkap.nl/book.htm/0-7923-8198-X">Kluwer Academic
									Publishers</a> </li>
							<li class="MsoNormal">Huan Liu and Hiroshi Motoda, “Computational Methods of
								Feature Selection”, editors, 2008, Chapman and Hall/CRC Press. </li>
							<li class="MsoNormal">H. Liu and Z. Zhao. "Manipulating Data and
								Dimensionality Reduc-tion Methods: Feature Selection", in
								Encyclopedia of Complexity and Systems Science, Robert Meyers (Ed.),
								Springer.&nbsp; 2009. </li>
							<li class="MsoNormal">H. Liu. "Feature Selection: An Overview", in
								Encyclopedia of Machine Learning, Claude Sammut (Ed.), Springer.
								Forthcoming.</li>
							<li class="MsoNormal">Z. Zhao and H. Liu. "On Interacting Features in
								Subset Selection", in Encyclopedia of Data Warehousing and Mining,
								2nd Edition, Idea Group, Inc. pp 1079 -- 1084, September, 2008.</li>
						</ul>
					</ul>

					<ul style="margin-top:0in" type="disc">
						<li class="MsoNormal"><b>Technical Reports</b> </li>
						<ul style="margin-top:0in" type="circle">
							<li class="MsoNormal">Z. Zhao and H. Liu. ``Semi-supervised Feature Selection
								via Spectral Analysis", Technical Report, <a
									href="http://www.public.asu.edu/~huanliu/papers/ssfs.pdf">TR-06-022</a>,
								Department of Computer Science and Engineering, Arizona State University,
								Tempe, AZ 85287, 2006. </li>
							<li class="MsoNormal">Y. Ye, L. Yu, and H. Liu.&nbsp; ``Sparse Linear
								Discriminant Analysis", Technical Report, TR-06-010, Department of
								Computer Science and Engineering, Arizona State University, Tempe, AZ
								85287, 2006.</li>
						</ul>
						<li><strong>Thesis</strong></li>
						<ul>
							<li> Z. Zhao. Spectral Feature Selection for Mining Ultrahigh Dimensional Data [<a
									href="http://www.public.asu.edu/~zzhao15/papers/zhaozheng_2010_thesis.pdf">PDF</a>]
							</li>
						</ul>
						<li><strong>Resources </strong></li>
						<ul>
							<li> <a href="http://featureselection.asu.edu/">Feature Selection Repository</a></li>
							<li> <a href="http://www.public.asu.edu/~jye02/Software/SLEP/index.htm">SLEP: A Sparse
									Learning Package</a></li>
						</ul>
					</ul>



					<h2>Related Activities</h2>

					<ul style="margin-top:0in" type="disc">
						<li class="MsoNormal"><strong>Workshop on Feature Selection in Data Mining (FSDM 10)</strong>
							[<a href="http://featureselection.asu.edu/">link</a>]<br>
							The proceedings of FSDM 2010 has been published by <a
								href="http://jmlr.csail.mit.edu/proceedings/papers/v10/">JMLR Workshop and Conference
								Proceedings</a></li>
						<li class="MsoNormal"> <strong>Tutorial at SDM10:&nbsp;</strong><a
								href="http://www.public.asu.edu/~jye02/SDM10/Sparse-SDM10.pdf">Mining Sparse
								Representations: Formulations, Algorithms, and Applications</a> </li>
						<li class="MsoNormal"><b>SIAM Data Mining SDM 2007 Tutorial: </b><span style="color:blue"><a
									href="http://www.cs.binghamton.edu/~lyu/SDM07/DR-SDM07.pdf">Dimensionality
									Reduction for Data Mining - Techniques, Applications, and Trends</a></span> </li>
						<li class="MsoNormal"><b>AAAI
								2005 Tutorial: </b><a
								href="http://www.aaai.org/Conferences/National/2005/tutorials05.html">Notes on
								Downsizing Data for High Performance in
								Learning - Feature Selection Methods</a>, <a
								href="http://www.public.asu.edu/~huanliu/papers/AAAI05-FeatureSelectionTutorial.zip">pdf.zip</a>.
						</li>
					</ul>

					<h2>Project Members</h2>

					<ul style="margin-top:0in" type="disc">
						<li class="MsoNormal"><a href="http://www.public.asu.edu/~huanliu/">Huan Liu</a>
							(PI)</li>
						<li class="MsoNormal"><a href="http://www.public.asu.edu/~jye02/">Jieping Ye</a>
							(Co-PI)</li>
						<li class="MsoNormal"><a href="http://www.public.asu.edu/~zzhao15/">Zheng Zhao</a> (Successfully
							defensed his PhD dissertation, joined SAS institute)</li>
						<li class="MsoNormal"> <a href="mailto:salelyan@asu.edu">Salem Alelyani</a> (Graduate, PhD)</li>
						<li class="MsoNormal"><a href="http://www.public.asu.edu/~lyuan9/">Lei Yuan</a> (Graduate, PhD)
						</li>
						<li class="MsoNormal"> <a href="mailto:sssharma@asu.edu">Shashvata Sharma</a> (Finished her
							graduate study for master degree, joined Microsoft)</li>
						<li class="MsoNormal"><a href="mailto:Fred.Morstatter@asu.edu">Fred Morstatter</a>
							(Undergraduate) </li>
						<li class="MsoNormal"> <a href="mailto:aanand11@asu.edu">Aneeth Anand</a> (Graduate, Master)
						</li>
					</ul>

					<h2>Acknowledgments</h2>

					<p class="MsoNormal">This project is sponsored by NSF (#0812551), 9/2008 -
						8/2011. </p>

				</div>

				<div class="entry">
					<a name="research">
						<h2 class="STYLE1">Description of Research</h2>
					</a>
					<p>Feature selection aims to choose a subset of original features according to a selection
						criterion. It is an important technique that is widely used in pattern analysis. Feature
						selection removes irrelevant and redundant features and brings about many benefits: giving more
						reliable parameter estimates, reducing computational cost and memory usage, improving learning
						performance, and providing better result comprehensibility [Guyo-Elis03,Liu-Moto98c]. According
						to the way of utilizing label information, feature selection algorithms can be categorized as
						supervised algorithms [West-etal03, Robn-Kono03], unsupervised algorithms [Dy-Brod04,He-etal05]
						or semi-supervised algorithms [zhao-sdm07,xu-ijcai-09]. From the perspective of selection
						strategy, feature selection algorithms broadly fall into three models: filter, wrapper or
						embedded [Guyo-Elis03]. The filter model evaluates features without involving any learning
						algorithm. The wrapper model requires a learning algorithm and uses its performance to evaluate
						the goodness of features. Algorithms of the embedded model, e.g., C4.5 [Quin93] and LARS
						[efro-etal04], incorporate feature selection as a part of learning process, and use the
						objective function of the learning model to guide searching for relevant features. In addition,
						feature selection algorithms may return either a subset of features [Yu-Liu03,Hall00] or the
						weights of all features measuring their utility [Aha98,Robn-Kono03]. Hence, they can also be
						categorized as subset selection algorithms or feature weighting algorithms. As an important
						technique, feature selection has been applied to various areas: computer vision [Dy-etal03],
						text mining [Geor03], and bioinformatics [Saeys2007], to name a few.</p>
					<p>The task of this depository is to collect the most popular algorithms that have been developed in
						the feature selection research area to serve as a platform to facilitate their application,
						comparison and joint study. You are encouraged to donate your algorithms and data sets to our
						depository.</p>
					<p>-------------------Reference---------------------</p>
					<p> <a name="Guyo-Elis03" id="Guyo-Elis03">[Guyo-Elis03</a>] Guyon, I. &amp; Elisseeff, A. An
						introduction to variable and feature selection Journal of Machine Learning Research, 2003, 3,
						1157-1182 <br>
						<a name="Liu-Moto98c" id="Liu-Moto98c">[Liu-Moto98c</a>] &nbsp;Liu, H. &amp; Motoda, H. Feature
						Selection for Knowledge Discovery and Data Mining Boston: Kluwer Academic Publishers, 1998 <br>
						<a name="West-etal03" id="West-etal03">[West-etal03</a>] Weston, J.; Elisseff, A.; Schoelkopf,
						B. &amp; Tipping, M. Use of the zero norm with linear models and kernel methods Journal of
						Machine Learning Research, 2003, 3, 1439-1461 <br>
						<a name="Robn-Kono03" id="Robn-Kono03">[Robn-Kono03</a>] Sikonja, M. R. &amp; Kononenko, I.
						Theoretical and empirical analysis of Relief and ReliefF Machine Learning, 2003, 53, 23-69 <br>
						<a name="Dy-Brod04" id="Dy-Brod04">[Dy-Brod04</a>] Dy, J. G. &amp; Brodley, C. E. Feature
						Selection for Unsupervised Learning J. Mach. Learn. Res., MIT Press, 2004, 5, 845-889 <br>
						<a name="He-etal05" id="He-etal05">[He-etal05</a>] He, X.; Cai, D. &amp; Niyogi, P. Weiss, Y.;
						Schölkopf, B. &amp; Platt, J. (ed.) Laplacian Score for Feature Selection Advances in Neural
						Information Processing Systems 18, MIT Press, 2005 <br>
						<a name="zhao-sdm07" id="zhao-sdm07">[zhao-sdm07</a>] Zhao, Z. &amp; Liu, H. Semi-supervised
						Feature Selection via Spectral Analysis Proceedings of SIAM International Conference on Data
						Mining (SDM), 2007 <br>
						<a name="xu-ijcai-09" id="xu-ijcai-09">[xu-ijcai-09</a>] Xu, Z.; Jin, R.; Ye, J.; Lyu, M. R.
						&amp; King, I. Discriminative semi-supervised feature selection via manifold regularization
						IJCAI' 09: Proceedings of the 21th International Joint Conference on Artificial Intelligence,
						2009 <br>
						<a name="Quin93" id="Quin93">[Quin93</a>] Quinlan, J. R. C4.5: Programs for Machine Learning
						Morgan Kaufmann, 1993 <br>
						<a name="efro-etal04" id="efro-etal04">[efro-etal04</a>] Efron, B.; Hastie, T.; Johnstone, I.
						&amp; Tibshirani, R. Least Angle Regression Annals of Statistics, 2004, 32, 407-49 <br>
						<a name="Yu-Liu03" id="Yu-Liu03">[Yu-Liu03</a>] Yu, L. &amp; Liu, H. Fawcett, T. &amp; Mishra,
						N. (ed.) Feature Selection for High-Dimensional Data: A Fast Correlation-Based Filter Solution
						Proceedings of the 20th International Conference on Machine Learning (ICML-03),, Morgan
						Kaufmann, 2003, 856-863 <br>
						<a name="Hall00" id="Hall00">[Hall00</a>] Hall, M. A. Correlation-based Feature Selection for
						Discrete and Numeric Class Machine Learning Proceedings of the Seventeenth International
						Conference on Machine Learning, 2000, 359-366 <br>
						<a name="Aha98" id="Aha98">[Aha98</a>] Aha, D. W. Feature Weighting for Lazy Learning Algorithms
						Feature Extraction, Construction and Selection: A Data Mining Perspective, 1998, 13-32 <br>
						<a name="Dy-etal03" id="Dy-etal03">[Dy-etal03</a>] Dy, J. G.; Brodley, C. E.; Kak, A. C.;
						Broderick, L. S. &amp; Aisen, M. A. Unsupervised Feature Selection Applied to Content-Based
						Retrieval of Lung Images IEEE Transactions on Pattern Analysis and Machine Intelligence, 2003,
						25, 373-378 <br>
						<a name="Geor03" id="Geor03">[Geor03</a>] Forman, G. An Extensive Empirical Study of Feature
						Selection Metrics for Text Classification Journal of Machine Learning Research, 2003, 3,
						1289-1305 <br>
						<a name="Saeys2007" id="Saeys2007">[Saeys2007</a>] Saeys, Y.; Inza, I. &amp; Larrañaga, P. A
						review of feature selection techniques in bioinformatics. Bioinformatics, 2007, 23, 2507-2517
					</p>
				</div>
			</div>
		</div>
		<!-- end #sidebar -->
		<div style="clear: both;">&nbsp;</div>
	</div>
	<!-- end #page -->
	<div id="footer">
		<p>© 2020 DMML @ ASU. All rights reserved.</p>
	</div>
	<!-- end #footer -->


</body>

</html>